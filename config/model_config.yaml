llama-3.1-8b:
  hf_key: "meta-llama/Llama-3.1-8B-Instruct"
  question_start_tag: "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 26 Jul 2024\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n"
  question_end_tag: "<|eot_id|>"
  answer_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
  flash_attention2: "true"
  gradient_checkpointing: "true"
phi-3.5:
  hf_key: "microsoft/Phi-3.5-mini-instruct"
  question_start_tag: "<|user|>\n"
  question_end_tag: "<|end|>\n"
  answer_tag: "<|assistant|>\n"
  flash_attention2: "true"
  gradient_checkpointing: "true"
llama2-7b:
  hf_key: "NousResearch/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "true"
  gradient_checkpointing: "true"
  ft_model_path: "locuslab/tofu_ft_llama2-7b" #this model will be used for unlearning by default
phi:
  hf_key: "microsoft/phi-1_5"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "locuslab/tofu_ft_phi-1.5"
stablelm:
  hf_key: "stabilityai/stablelm-3b-4e1t"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_stablelm/checkpoint-625"
pythia-1.4:
  hf_key: "EleutherAI/pythia-1.4b-deduped"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
pythia-160m:
  hf_key: "EleutherAI/pythia-160m-deduped"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"